{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = (1,2,2)\n",
    "np.prod(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "from DynGenModels.trainer.configs import Training_Configs\n",
    "\n",
    "@dataclass\n",
    "class Configs:#(Training_Configs):\n",
    "    DATA : str = None\n",
    "    DATA_SOURCE : str = 'noise'\n",
    "    DATA_TARGET : str = 'mnist'\n",
    "    dim_input : int = None\n",
    "    input_shape : Tuple[float] = field(default_factory = lambda : (1, 28, 28))\n",
    "    batch_size = 10\n",
    "    MODEL : str = 'Unet'\n",
    "    dim_hidden : int = 32\n",
    "    num_res_blocks : int = 1\n",
    "    DYNAMICS : str = 'CondFlowMatch'\n",
    "    sigma : float = 0.001\n",
    "    augmented : bool = False\n",
    "    t0 : float = 0.0\n",
    "    t1 : float = 1.0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.DATA = self.DATA_SOURCE + '_to_' + self.DATA_TARGET\n",
    "        self.dim_input = np.prod(self.input_shape)\n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, configs: dataclass):\n",
    "        self.configs = configs\n",
    "        self.get_target_data()\n",
    "        self.get_source_data()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        output = {}\n",
    "        output['target'] = self.target[idx]\n",
    "        output['source'] = self.source[idx]\n",
    "        output['context'] = self.target_label[idx]\n",
    "        output['mask'] = torch.ones_like(output['target'])\n",
    "        return output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "\n",
    "    def get_target_data(self):\n",
    "        \n",
    "        if self.configs.DATA_TARGET == 'mnist':\n",
    "            self.data_1 = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "        \n",
    "        elif self.configs.DATA_TARGET == 'emnist':\n",
    "            self.data_1 = datasets.EMNIST(root='../data', split='letters', train=True, download=True, transform=transforms.ToTensor())\n",
    "        \n",
    "        elif self.configs.DATA_TARGET == 'fashion':\n",
    "             self.data_1 = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "        \n",
    "        self.target = [d[0] for d in self.data_1]\n",
    "        self.target_label = [d[1] for d in self.data_1]\n",
    "        \n",
    "    def get_source_data(self):\n",
    "\n",
    "        if self.configs.DATA_SOURCE == 'mnist':\n",
    "            self.data_0 = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "       \n",
    "        elif self.configs.DATA_SOURCE == 'emnist':\n",
    "            self.data_0 = datasets.EMNIST(root='./data', split='letters', train=True, download=True, transform=transforms.ToTensor())\n",
    "       \n",
    "        elif self.configs.DATA_SOURCE == 'fashion':\n",
    "             self.data_0 = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "        else:\n",
    "            self.data_0 = self.data_1\n",
    "\n",
    "        self.source = [d[0] for d in self.data_0] if self.configs.DATA_SOURCE is not None else [torch.rand_like(d[0]) for d in self.data_0]\n",
    "        self.source_label = [d[1] for d in self.data_0] if self.configs.DATA_SOURCE is not None else [0] * len(self.data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class MNISTDataLoader:\n",
    "\n",
    "    def __init__(self, datasets: Dataset, configs: dataclass): # type: ignore\n",
    "\n",
    "        self.datasets = datasets        \n",
    "        self.fracs = configs.data_split_fracs\n",
    "        self.batch_size = configs.batch_size\n",
    "        self.dataloader()\n",
    "\n",
    "    def train_val_test_split(self, shuffle=False):\n",
    "        assert np.abs(1.0 - sum(self.fracs)) < 1e-3, \"Split fractions do not sum to 1!\"\n",
    "        total_size = len(self.datasets)\n",
    "        train_size = int(total_size * self.fracs[0])\n",
    "        valid_size = int(total_size * self.fracs[1])\n",
    "\n",
    "        #...define splitting indices\n",
    "\n",
    "        idx = torch.randperm(total_size) if shuffle else torch.arange(total_size)\n",
    "        idx_train = idx[:train_size].tolist()\n",
    "        idx_valid = idx[train_size : train_size + valid_size].tolist()\n",
    "        idx_test = idx[train_size + valid_size :].tolist()\n",
    "        \n",
    "        #...Create Subset for each split\n",
    "\n",
    "        train_set = Subset(self.datasets, idx_train)\n",
    "        valid_set = Subset(self.datasets, idx_valid) if valid_size > 0 else None\n",
    "        test_set = Subset(self.datasets, idx_test) if self.fracs[2] > 0 else None\n",
    "\n",
    "        return train_set, valid_set, test_set\n",
    "\n",
    "\n",
    "    def dataloader(self):\n",
    "\n",
    "        print(\"INFO: building dataloaders...\")\n",
    "        print(\"INFO: train/val/test split ratios: {}/{}/{}\".format(self.fracs[0], self.fracs[1], self.fracs[2]))\n",
    "        \n",
    "        train, valid, test = self.train_val_test_split(shuffle=True)\n",
    "        self.train = DataLoader(dataset=train, batch_size=self.batch_size, shuffle=True)\n",
    "        self.valid = DataLoader(dataset=valid,  batch_size=self.batch_size, shuffle=False) if valid is not None else None\n",
    "        self.test = DataLoader(dataset=test,  batch_size=self.batch_size, shuffle=True) if test is not None else None\n",
    "\n",
    "        print('INFO: train size: {}, validation size: {}, testing sizes: {}'.format(len(self.train.dataset),  # type: ignore\n",
    "                                                                                    len(self.valid.dataset if valid is not None else []),  # type: ignore\n",
    "                                                                                    len(self.test.dataset if test is not None else []))) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configs(DATA='noise_to_mnist', DATA_SOURCE='noise', DATA_TARGET='mnist', dim_input=784, input_shape=(1, 28, 28))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configs()\n",
    "config.workdir = './'\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: building dataloaders...\n",
      "INFO: train/val/test split ratios: 1.0/0.0/0.0\n",
      "INFO: train size: 60000, validation size: 0, testing sizes: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAAEV0lEQVR4nH2QfTAbdhjHH0kkwpYwb9UypFK1SnFeeg1DitJuNWH6Mi8tqVK9XlddsOtZqW42a6uY10NblzSj1dvKOi+TlFHrUCdBRMK8a1FWJkT3i/2RVNXu8v3r97v7fO77PA+81xOQ7Hj8UoJlM+85o619bgnTgjt8usWdJ0xaBQ3B2HBrUwRGk0NxF9e+HaV1fmIYW9FvKcoZ6nTh7Nck4my9Z32t2P0vmc5cY/w/Pxquznp3G7IuuWxzjRE+0mSyjSVhkX9GZ2QVgL+H2YTYW8Ik8Us57sRnrTJNnhbZJ+P9mO4IQW7mLeLWpCd640aP8Lu+fLBYHNiz5WdNO94zTbpBH9R1wyQPF+3U/77unslxDy+qU1fWgr+1Cnmnco1DBAAghn28wWReu+xsPm2hXeJYN0dpEISKX+hg77AjM2aqDXxUhDVCaAsAwHXUp/Om0SBFwDKRxP97MPWMS+l3pDR9akm1y3Yq/guxHXbTdA5gW0Fa/1EiXe0dg11Wkla+knL5DXnbJpsU1VuJWk5F55ibGnkIIav1xriq3TZTzIjelNVpEalVcWPK3DU12/qIQCpq4aiXec0mvHUc/rET3eynh2Zu2VjPeyqzTo08Pf94xz5ZdXzH5bMqJGQjn7n+Sr9t8krW3DpmiHUY9Jrdf7XXJSmkay+ndmrZRl9FtCL0kx4AgBlC6Pd1sWa3XhrQmuryTtSM9lpwB+869bmTfzi9+sSEUg0AANErCKmG9EUICc3VHi6cFPh5h7xOG39bKrT8DR9KLxnl/CEvD8S6mUoBAPRY2gChpS8Bnx8AALsC89XmHK2s2I/Eospo4XQkAnvTHn/+nbFMrnfjtVIAAAOEEELLcrkcIYQQUpDVx2kyKyCQSiaXSCclh1/0FZ4qrKDEvrvWfp1hZYwAAJaKlACAJxAI6hFf72iSf1cZf//m+LA04++gILpO+0mj4EyeZf1yeJRSRXyN1FksnkYIqRuhd8YS+aKgtisVByY6zvjivJpZeUKm2yszIyOxiiAyGAwGo5LBoEPnGxFHcD8QpaR/MHB+PtRTZMbplvjqUBMLmoYXch92qJBlAQCAADYlYiCNJBjStSOLPpvOydPFBCY8PhbTrLjAjVqc2cy+1Ug+ahXbqDgaHnmx3jBkzvnh/f4uSXDPLDvuYKT3/8QNwaTWtGS1tKeIxvHcJpNabNvN7bnp+rJftWh+VUaaRFy6YrB8OHZBO5jInu9K9y+ky3jWzyqHyKZrY/6aRBjP6an33mNNEfPzZPwLbnFTRWKmw4BhNvJYdN7Mnl1FSKinemt9hAbkYsxMtR7PltVwrvNqZktI1oIipghHmzmyY5No94vlQKBU/UEhjcWdqQ79DcrJ1b/4IwHLw5+2RdtVXiE+OMQEDcH1Ycv2rgzUjDxPxtrurCr/xrNvtI2xgK3VmqMSNIlaIgm1roy8Z3IlMXvCb84icZYq/3Afxd4sjDbmE6tB/A/51ulJNH9YUAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.DATA_SOURCE = None\n",
    "config.DATA_TARGET = 'mnist'\n",
    "data = MNIST_Dataset(config)\n",
    "dataloader = MNISTDataLoader(data, config)\n",
    "\n",
    "transform = ToPILImage()\n",
    "\n",
    "for batch in dataloader.train:\n",
    "    pair = torch.cat([batch['source'][0].squeeze(), batch['target'][0].squeeze()], dim=1)\n",
    "    img = transform(pair)\n",
    "    break\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: building dataloaders...\n",
      "INFO: train/val/test split ratios: 1.0/0.0/0.0\n",
      "INFO: train size: 60000, validation size: 0, testing sizes: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAACaUlEQVR4nI3Uv2uTQRgH8O/z3OVHExprY9pUxf4wItil2sFBuoggdXAQVOzm4FqLg3+ACi52cZPODrq4iOImBbEIQhVBQW2hamxr09ikSfPjvXscSqy9e8Hc8ML7cB++zwN3BwAAWAEYBIAUABDaWwQAvdPyZuLK3fyP87ptAwxMTUT1b8mXs7o7UTIzt9qEtye5UjcKCS6JNSqW2sq2BYdfr0oE1toamRgTm2r/3Ln/QA0AN2rQSsciFsSE+la9Y/2sv5XvfZxxYC+hC9WFja2NurbJA+lOHXCy4sLLU9Nu4n7Ln16tN7nJqU0j1WxupAu5dy48hp8u3GPNXLEvSbVMo6OaaurPQjjkwU08+7dxANhopK4NxjOGTaFTfc1XqMei15uxvOtPA8ikm9H3fWtL9ehW8KFQi62M6tJSwoMnPHjcqOzjozTUKUrFS+XlX5WE4uv3HXfk4lrZKYGTiEi+uLay/H21UFwtPhh5/mjA3TRqZ91E2AqaqFYECBQZ6R6eH/caBfDUhcSqAbBAoDRzIyiDCNZhp7DiQjECwIJIYFnACxDx8i4EuxJ556vAzICQxEP6HBt7WfChILkoJBAQGyv9IfCw3IEPgbQCASKkIBILeQNOz8+GQEHNkCUA1moEGT8wd8kptBKJSAggEJGN+4m56IswSDgYNQSAQAIJeXTO0JPwxB4SagWbrp363yXObWnN2M0AMYiJYeIZr9WrD4PwViNksT2ZZizG4B6AL4FTaY3TEaAh3GQLW9NN79nASbewDS3G99p9wlAawLfE0FtvxnAouDmZZmOktlzaE5T7894R99Yf9+7qMFbQHYYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configs()\n",
    "config.DATA_SOURCE = 'fashion'\n",
    "config.DATA_TARGET = 'mnist'\n",
    "data = MNIST_Dataset(config)\n",
    "dataloader = MNISTDataLoader(data, config)\n",
    "\n",
    "transform = ToPILImage()\n",
    "\n",
    "for batch in dataloader.train:\n",
    "    pair = torch.cat([batch['source'][0].squeeze(), batch['target'][0].squeeze()], dim=1)\n",
    "    img = transform(pair)\n",
    "    break\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchcfm.models.unet import UNetModel\n",
    "\n",
    "class Unet(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.device = configs.DEVICE\n",
    "        self.unet = UNetModel(dim=configs.dim_input, \n",
    "                              num_channels=configs.dim_hidden, \n",
    "                              num_res_blocks=configs.num_res_blocks)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, t, x, context=None, mask=None):\n",
    "        x = self.unet(t, x, y=context)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (unet): UNetModelWrapper(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttentionLegacy()\n",
       "          (proj_out): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttentionLegacy()\n",
       "          (proj_out): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttentionLegacy()\n",
       "          (proj_out): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DynGenModels.trainer.trainer import DynGenModelTrainer\n",
    "from DynGenModels.dynamics.cnf.condflowmatch import OptimalTransportFlowMatching as dynamics\n",
    "\n",
    "cfm = DynGenModelTrainer(dynamics = dynamics(config),\n",
    "                         model = Unet(config), \n",
    "                         dataloader = dataloader, \n",
    "                         configs = config)\n",
    "\n",
    "cfm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
