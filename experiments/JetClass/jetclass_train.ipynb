{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPiC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#=====================================================================\n",
      "INFO: created directory: ../../results/test.CFM.EPiC.2024.02.23_13h43\n",
      "#=====================================================================\n",
      "+----------------------+-----------------+\n",
      "| Parameters           | Values          |\n",
      "+----------------------+-----------------+\n",
      "| NAME                 | test            |\n",
      "| DATASET              | jetclass        |\n",
      "| DATA_SOURCE          | noise           |\n",
      "| DATA_TARGET          | top             |\n",
      "| MAX_NUM_CONSTITUENTS | 30              |\n",
      "| FEATURES             | constituents    |\n",
      "| PREPROCESS           | ['standardize'] |\n",
      "| DIM_INPUT            | 3               |\n",
      "| DEVICE               | cuda:1          |\n",
      "| OPTIMIZER            | Adam            |\n",
      "| LR                   | 0.0001          |\n",
      "| WEIGHT_DECAY         | 0.0             |\n",
      "| OPTIMIZER_BETAS      | [0.9, 0.999]    |\n",
      "| OPTIMIZER_EPS        | 1e-08           |\n",
      "| OPTIMIZER_AMSGRAD    | False           |\n",
      "| GRADIENT_CLIP        | 1.0             |\n",
      "| SCHEDULER            |                 |\n",
      "| SCHEDULER_T_MAX      |                 |\n",
      "| SCHEDULER_ETA_MIN    |                 |\n",
      "| SCHEDULER_GAMMA      |                 |\n",
      "| SCHEDULER_STEP_SIZE  |                 |\n",
      "| EPOCHS               | 1               |\n",
      "| BATCH_SIZE           | 1024            |\n",
      "| DATA_SPLIT_FRACS     | [0.8, 0.2, 0.0] |\n",
      "| NUM_WORKERS          | 0               |\n",
      "| PIN_MEMORY           | False           |\n",
      "| EARLY_STOPPING       |                 |\n",
      "| MIN_EPOCHS           |                 |\n",
      "| PRINT_EPOCHS         | 10              |\n",
      "| FIX_SEED             |                 |\n",
      "| MODEL                | EPiC            |\n",
      "| POOLING              | mean_sum        |\n",
      "| DIM_HIDDEN           | 300             |\n",
      "| TIME_EMBEDDING       | sinusoidal      |\n",
      "| DIM_TIME_EMB         | 12              |\n",
      "| DIM_GLOBAL           | 10              |\n",
      "| NUM_EPIC_LAYERS      | 6               |\n",
      "| USE_SKIP_CONNECTIONS | True            |\n",
      "| ACTIVATION           | ReLU            |\n",
      "| DYNAMICS             | CFM             |\n",
      "| SIGMA                | 1e-05           |\n",
      "| AUGMENTED            | False           |\n",
      "| T0                   | 0.0             |\n",
      "| T1                   | 1.0             |\n",
      "| SAMPLER              | NeuralODE       |\n",
      "| SOLVER               | midpoint        |\n",
      "| NUM_SAMPLING_STEPS   | 200             |\n",
      "| SENSITIVITY          | adjoint         |\n",
      "| ATOL                 |                 |\n",
      "| RTOL                 |                 |\n",
      "| NUM_GEN_SAMPLES      | 10000           |\n",
      "+----------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 13:43:52.210096: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-23 13:43:52.255287: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-23 13:43:52.256340: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 13:43:53.004354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "number of training parameters: 2526746\n",
      "start training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: building dataloaders...\n",
      "INFO: train/val/test split ratios: 0.8/0.2/0.0\n",
      "INFO: train size: 80000, validation size: 20000, testing sizes: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0b70d60eb14bf0b7283e06ecb1ec94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDynGenModels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperiment\u001b[39;00m \u001b[39mimport\u001b[39;00m Experiment\n\u001b[1;32m      4\u001b[0m cfm \u001b[39m=\u001b[39m Experiment(Config_JetClass_EPiC_CondFlowMatch,\n\u001b[1;32m      5\u001b[0m                  NAME \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                  DATA_SOURCE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnoise\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m                  NUM_SAMPLING_STEPS \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m,\n\u001b[1;32m     26\u001b[0m                  DEVICE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda:1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m cfm\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/DynGenModels/src/DynGenModels/models/experiment.py:202\u001b[0m, in \u001b[0;36mExperiment.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/DynGenModels/src/DynGenModels/models/experiment.py:65\u001b[0m, in \u001b[0;36mDefineModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m#...train\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 65\u001b[0m     train\u001b[39m.\u001b[39;49mupdate(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, loss_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdynamics\u001b[39m.\u001b[39;49mloss, dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader\u001b[39m.\u001b[39;49mtrain, optimizer\u001b[39m=\u001b[39;49moptimizer) \n\u001b[1;32m     66\u001b[0m     valid\u001b[39m.\u001b[39mupdate(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, loss_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamics\u001b[39m.\u001b[39mloss, dataloader\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader\u001b[39m.\u001b[39mvalid, seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfix_seed)\n\u001b[1;32m     67\u001b[0m     TERMINATE, IMPROVED \u001b[39m=\u001b[39m valid\u001b[39m.\u001b[39mcheckpoint(min_epochs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_epochs, early_stopping\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mearly_stopping)\n",
      "File \u001b[0;32m~/DynGenModels/src/DynGenModels/models/utils.py:25\u001b[0m, in \u001b[0;36mTrain_Step.update\u001b[0;34m(self, model, loss_fn, dataloader, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m     loss_current \u001b[39m=\u001b[39m loss_fn(model, batch)\n\u001b[1;32m     26\u001b[0m     loss_current\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()  \n",
      "File \u001b[0;32m~/DynGenModels/src/DynGenModels/dynamics/cnf/condflowmatch.py:41\u001b[0m, in \u001b[0;36mConditionalFlowMatching.loss\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefine_source_target_coupling(batch)\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_time() \n\u001b[0;32m---> 41\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_gaussian_conditional_path()\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconditional_vector_fields()\n\u001b[1;32m     43\u001b[0m vt \u001b[39m=\u001b[39m model(x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath, t\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/DynGenModels/src/DynGenModels/dynamics/cnf/condflowmatch.py:27\u001b[0m, in \u001b[0;36mConditionalFlowMatching.sample_gaussian_conditional_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_gaussian_conditional_path\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\" sample conditional path: x_t ~ p_t(x|x_0, x_1)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m\t\"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \tmean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx1 \u001b[39m+\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt) \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx0\n\u001b[1;32m     28\u001b[0m \tstd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma_min\n\u001b[1;32m     29\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m mean \u001b[39m+\u001b[39m std \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrandn_like(mean)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "from DynGenModels.configs.registered_experiments import Config_JetClass_EPiC_CondFlowMatch\n",
    "from DynGenModels.models.experiment import Experiment\n",
    "\n",
    "cfm = Experiment(Config_JetClass_EPiC_CondFlowMatch,\n",
    "                 NAME = 'test',\n",
    "                 DATA_SOURCE = 'noise',\n",
    "                 DATA_TARGET = 'top',\n",
    "                 MAX_NUM_CONSTITUENTS = 30,\n",
    "                 DYNAMICS = 'CFM',\n",
    "                 DATA_SPLIT_FRACS = [0.8, 0.2, 0.0],\n",
    "                 PREPROCESS = ['standardize'],\n",
    "                 BATCH_SIZE = 1024,\n",
    "                 EPOCHS = 1,\n",
    "                 PRINT_EPOCHS = 10,\n",
    "                 LR = 1e-4,\n",
    "                 GRADIENT_CLIP = 1.0,\n",
    "                 DIM_HIDDEN = 300,\n",
    "                 TIME_EMBEDDING = 'sinusoidal',\n",
    "                 USE_SKIP_CONNECTIONS = True,\n",
    "                 DIM_TIME_EMB = 12,\n",
    "                 DIM_GLOBAL = 10,\n",
    "                 NUM_EPIC_LAYERS = 6,\n",
    "                 SIGMA = 1e-5,\n",
    "                 SOLVER ='midpoint',\n",
    "                 NUM_SAMPLING_STEPS = 200,\n",
    "                 DEVICE = 'cuda:1')\n",
    "\n",
    "cfm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 30, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm.dataset.target_preprocess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1619,  0.6288],\n",
       "         [ 0.2620,  0.0207],\n",
       "         [ 1.5959,  1.0015],\n",
       "         ...,\n",
       "         [-0.8465,  1.0454],\n",
       "         [-0.0688, -0.1723],\n",
       "         [-0.7292, -0.4705]],\n",
       "\n",
       "        [[-0.0336, -1.0330],\n",
       "         [-1.0717,  0.5368],\n",
       "         [-0.9542,  1.3141],\n",
       "         ...,\n",
       "         [ 0.5066,  0.8716],\n",
       "         [-1.4672,  2.3473],\n",
       "         [-0.4197, -1.1293]],\n",
       "\n",
       "        [[-0.4106, -0.8874],\n",
       "         [-0.5636,  0.2448],\n",
       "         [-1.2509,  2.7924],\n",
       "         ...,\n",
       "         [-1.2219, -1.6121],\n",
       "         [ 0.6518,  0.8252],\n",
       "         [-1.1669, -0.4669]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3596, -1.3204],\n",
       "         [-0.8806,  1.2772],\n",
       "         [ 0.8163,  1.6567],\n",
       "         ...,\n",
       "         [ 0.4433, -2.6409],\n",
       "         [ 0.2539,  0.2183],\n",
       "         [-0.8602, -0.8261]],\n",
       "\n",
       "        [[-0.9441,  0.1959],\n",
       "         [-2.9732,  0.1105],\n",
       "         [-1.0108,  0.0592],\n",
       "         ...,\n",
       "         [-1.4322, -0.3400],\n",
       "         [ 0.3598, -1.5578],\n",
       "         [-1.9745,  0.5239]],\n",
       "\n",
       "        [[-0.2847, -0.7687],\n",
       "         [ 1.7495,  0.4779],\n",
       "         [ 0.0516,  0.0132],\n",
       "         ...,\n",
       "         [-0.9140,  1.2829],\n",
       "         [ 0.9107, -0.0756],\n",
       "         [ 0.5419,  1.1081]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm.dataset.source_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow_match_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
